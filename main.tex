%!TEX options = --shell-escape
\documentclass[master]{thesis-uestc}
%\usepackage{algorithm}
\usepackage{algpseudocode}
%\usepackage{listings}
%\newcommand{\thelstlisting}{\arabic{chapter}-\arabic{lstlisting}}
\lstset{
basicstyle=\tt,
%行号
numbers=left,
rulesepcolor=\color{red!20!green!20!blue!20},
escapeinside=``,
xleftmargin=2em,xrightmargin=2em, aboveskip=1em,
%背景框
framexleftmargin=1.5mm,
frame=box,
%背景色
% backgroundcolor=\color[RGB]{245,245,244},
%样式
%keywordstyle=\color{blue}\bfseries,
identifierstyle=\bf,
%numberstyle=\color[RGB]{0,192,192},
%commentstyle=\it\color[RGB]{96,96,96},
%stringstyle=\rmfamily\slshape\color[RGB]{128,0,0},
%显示空格
showstringspaces=false
}
\lstset{basicstyle=\ttfamily,
extendedchars=false,
escapechar=`,
language=C,
%commentstyle=\color{red}
}
\title{基于GPU的SDN网络并行业务量工程算法研究}
\author{张骞}
\begin{document}
\begin{chineseabstract}
业务量工程（Traffic Engineering）能够通过为业务选择合理的网络路由来达到充分利用网络资源、提高网络性能、满足Qos需求等目的。在SDN网络中，集中式的SDN控制器能够在全局拓扑上进行业务量工程，提高业务量工程的优化效果。然而，由于互联网应用的快速增加，短时间内会有大量业务到达SDN网络，同时，SDN网络的规模也相应增大，这要求SDN控制器能在短时间内在大网络拓扑上为大量业务计算路由，业务量工程的计算面临着时间上的挑战。所以，为了缩短SDN控制器的计算时间，本文充分挖掘业务量工程算法的并行特性，利用GPU来加速业务量工程算法。

针对SDN IP网络，本文首先将业务量工程问题建模成一个带链路容量约束的MILP模型。为了求解这个模型，本文提出了两种并行算法GA-PTEA（Genetic algorithm based parallel traffic engineering algorithm）和LR-PTEA（Lagrange relaxing based parallel traffic engineering algorithm)。其中，GA-PTEA将原来的业务量工程模型简化为基于备选路径的业务量工程模型，利用并行的遗传算法来求解业务量工程问题，并行加速比可达到20倍以上。LR-PTEA则采用了拉格朗日松弛的方法，首先通过松弛链路容量约束，将业务量工程问题分解为一批业务的最短路径计算问题，然后设计了基于GPU的并行算法来加速最短路的计算。LR-PTEA使用次梯度下降方法来求解拉格朗日对偶问题，为了加快次梯度算法的收敛速度，LR-PTEA采用了高效的次梯度步长更新方法，同时，LR-PTEA在求解对偶问题的过程中采用了快速的路径调整策略来获得对原问题目标函数的可行解。本文的实验发现基于GPU的LR-PTEA并行算法可以在短时间内得到业务量工程问题的优化解，与串行算法LR-STEA(Lagrange relaxing based serial route optimization algorithm)相比，加速比可达到6倍以上。

在SDN弹性光网络中，首先，为了简化频谱分配问题，本文采用分层图模型将弹性光网络中的频谱分配问题转化为路由选择问题。其次，为了优化弹性光网络中业务的路由代价，减小资源使用，降低阻塞率，本文提出了TESAA（traffic engineering and spectrum allocate algrithm）优化算法。最后，为了缩短SDN控制器的计算时间，我们对TESAA进行并行加速，分别针对无权图和带权图设计了基于GPU的并行路由算法。实验发现TESAA可以大大减小路由的代价、节省网络资源和有效降低业务的阻塞率，基于GPU的并行算法PTESAA（parallel TESAA)与串行算法STESAA(serial TESAA)相比，加速比可达到5倍。

\chinesekeyword{GPU，并行算法，业务量工程，路由优化，路由算法，SDN，弹性光网络，RSA，动态规划}
\end{chineseabstract}
\begin{englishabstract}

Traffic engineering refers to the process of optimizing the network utilization, minimizing network costs, improving network performance, and meeting QoS requirements by selecting reasonable network routes for the services. However, due to the rapid increase of Internet applications ,there will be a large number of services reaching the SDN network at the same time,the size of the SDN network will also increase accordingly.This makes SDN controllor needs to calculate a large-scale routing in a short time. To solve the problem of large-scale routing calculation in traffic engineering, we use GPU-based parallel algorithms to accelerate the traffic engineering algorithm.

For SDN IP networks, this paper first proposes a traffic engineering model with link capacity constraints. The utility function in the model is to minimize the routing cost. In order to solve this model,two parallel algorithms GA-PTEA (Genetic algorithm based parallel traffic engineering algorithm) and LR-PTEA (Lagrange relaxing based parallel traffic engineering algorithm) are proposed
Among them, GA-PTEA adopts a traffic engineering model based on alternative paths,and uses parallel genetic algorithms to solve the traffic engineering problems,The parallel acceleration ratio can reach more than 20 times. LR-PTEA uses a Lagrange relaxation-based traffic engineering model. First, the traffic engineering problem is decomposed into a batch of shortest path problems by relaxing the link capacity constraints,then the path calculation tasks are dispatched to GPU and executed concurrently on GPU.To improve the convergence speed,LR-PTEA uses efficient methods to adjust the calculated paths for a part of traffic demands and set the step size of subgradient algorithm for solving the Lagrangian dual problem in each iteration.The experiment in this paper found that LR-PTEA can get the optimized solution of the traffic engineering problem in a short time.The experiment also found that the the speedup of GPU-based LR-PTEA can reach up to 6 times.

For the SDN elastic optical network, this paper first uses the layered graph model to transform the spectrum allocation problem into a routing problem. In order to optimize the routing cost of services in the elastic optical network, reduce the network resource usage, and reduce the blocking rate, this paper proposes a TESAA (traffic engineering and spectrum allocation algrithm)framework.we use GPU to accelerated the calculation of TESAA.In the case of unweighted graphs,this paper proposes a parallel BFS algorithm to accelerate the TESAA framework. In the case of weighted graphs, this paper proposes a shortest path dynamic programming model with hops constraint, we designed a parallel dynamic programming algorithm to accelerate the caculation of TESAA. in our experiments,we found that TESAA can greatly reduce the cost of routing and effectively reduce the blocking rate of services,the seepdup of GPU-based parallel algorithm PTESAA(parallel TESAA) can reach up to 5 times.




\englishkeyword{GPGPU, Parallel Algorithm, Traffic Engineering, Route Optimization, Routing Algorithm, SDN, EON, RSA}
\end{englishabstract}
\thesistableofcontents
\thesisfigurelist
\thesistablelist
\thesischapterexordium
\section{研究背景与意义}

在网络中，为了充分利用网络资源、提高网络性能，我们需要为业务选择合适的网络路由，这被称为业务量工程（Traffic Engineering，TE，又被称为路由优化 routing optimization ，RO）问题。业务量工程问题的传统解决方法主要有以下两种\citing{shen}。第一，根据业务的流量模式来调整网络的权重以实现业务量工程。第二，在IP网络中通过MPLS来实现业务量工程。

软件定义网络(Software Defined Network，SDN)是一种创新的网络架构，与传统网络不同，SDN网络架构中引入了集中式的控制器，将网络的控制平面和数据平面分离开来\citing{OpenFlow} \citing{SDN}。SDN网络中的控制器负责对网络进行控制和调度，同时控制器通过向上提供编程接口，使得网络控制规则可以根据不同的需求进行设计，使得网络的控制设计更加灵活，网络管理人员可以更方便的更新各种网络应用和服务，而无需关心底层的数据平面管理。在SDN底层数据平面中，各种网络设备被抽象简化，数据流通过匹配控制器下发在设备中的流表规则来进行快速转发。和传统网络相比，SDN架构大大简化了网络设备的复杂功能，减小了网络成本。SDN架构中的控制器可以获得全网络的拓扑信息，同时，SDN控制器能够通过下发流表规则来对网络流进行细粒度的调度，所以在SDN架构下可以很容易地实现基于全局网络的业务量工程。微软 \citing{Microsoft}和谷歌 \citing{Google}的实验结果证明，在SDN网络架构的数据中心网络中，业务量工程能够在网络吞吐量和链路利用率上达到接近最优化性能的表现。

然而，SDN网络下的业务量工程为SDN控制器带来了较大的计算压力，原因有以下三点：第一，随着网络应用的快速增加，在SDN网络中短时间内可能会有大量业务到达控制器 \citing{application}，所以控制平面必须短时间内为大量业务计算路由；第二，为了适应大量业务的加入，网络规模也快速增大\citing{5G} \citing{DCN}；第三，SDN技术使网络能够几乎满负荷运行\citing{Secondrouting}，这意味着一旦网络流量发生重大变化或者网络链路出现故障，SDN控制器需要在短时间内重新计算出路由。因此，在大网络下对大量业务进行快速和高效的业务量工程成为了一个重要却困难的问题。

为了缩短SDN网络下业务量工程的计算时间，设计高效的并行算法是一种常见的解决思路。另外，由于业务量工程中大量业务之间的路由计算是相互独立的，这也为并行业务量工程算法的设计提供了可能性。同时，现今出现的商业服务器具有多核CPU和强大的GPU，为并行算法提供了一种低成本、高性能的计算环境，尤其是GPU，他具有大量的计算单元，现今的GPU能够同时调度和执行上千个线程，具有强大的并行计算能力。

GPGPU(general purpose programming on GPU)是指利用GPU进行通用计算（而不仅仅是图形学计算）的算法设计思想，为了简化GPU的通用程序设计模式，2007 年，Nvidia 发布了一种新的GPU编程模型CUDA( Compute Unified Device Architecture)\citing{CUDA}。与传统的GPU通用计算开发模式相比，CUDA编程更简单，功能更强大，应用领域更广泛\citing{CUDAR}。随着GPU硬件计算能力的不断提高和CUDA通用计算模型的流行，利用GPU来加速并行算法成为一个研究热点\citing{CUDAR}。结合SDN网络中业务量工程的可并行性质和GPU强大的通用并行计算能力，来设计高效的基于GPU的并行业务量工程算法能够有效降低业务量工程的计算时间，具有很重要的研究意义。



\section{国内外研究现状}
\subsection{SDN IP网络下业务量工程算法的研究现状}
过去十年间，随着IP网络中网络流量的迅速增加，业务量工程算法得到了大量的研究，论文 \citing{TESurvey, TEDef, TESurvey1}对业务量工程的研究进行了详尽的综述。大部分情况下业务量工程问题是一个NP难问题 \citing{NP, multi-commodity}，大量启发式算法\citing{TESurvey, TEDef, TESurvey1}被提出来解决这类业务量工程问题。然而，这些算法基本上都是串行算法，在大网络和大业务量的情况下，这些算法需要运行几分钟甚至是几个小时\citing{SDNTE, ParaTE1, multi-commodity}。由于执行时间较长，这些业务量工程算法仅作为离线工具使用\citing{Time}。为了减少计算时间，多篇论文\citing{mate, DATE}研究了分布式的路由优化算法，在分布式的业务量工程模型中，假设每个业务有一系列的备选路径，业务将总流量分配到各个路径上，各个路径上所承载的流量根据路径上的链路容量情况实时进行调整。但是，分布式的业务量工程算法依赖于精确实时的网络状态信息，而且在实际实现中收敛较慢。

另一方面，过去十年，GPU的计算能力得到了大幅度的提高，GPU通用计算模型得到大力发展\citing{GPUdeve, CUDA}，GPU的理论计算能力提高速度大大高于CPU的计算能力提高速度\citing{GPUdeve}。因此，许多基于GPU的并行算法被提出来求解一些整数规划问题，比如说旅行商问题\citing{TSP}，路线规划问题\citing{VRP}，最短路问题\citing{SSP1, SSP2}，最小生成树问题 \citing{MST}，现存的研究\citing{TSP, VRP, SSP1, SSP2, MST}表明基于GPU的并行算法可以比基于CPU的算法快十倍以上。

现今，对并行业务量工程算法的研究较少，文献\citing{ParaTE1, ParaTE2}对业务量工程问题提出了并行的算法，在论文\citing{ParaTE1}中，作者为alpha公平的业务量工程问题提出了一种很适合在FPGA和GPU上实现并行的算法，为了达到alpha公平的目标，论文 \citing {ParaTE1}假设一个业务需求需要被分到多条路径上，但是这个假设在实际中很难实现，这是因为，第一，如果业务流是细粒度的流（TCP/UDP），把业务分到不同的路径将导致网络数据包的乱序传递。第二，SDN网络需要使用更多的流表规则来将聚合的流分离成细粒度的流，但是SDN交换机上的流表匹配资源TCAM(ternary content addressable memory)是有限的。第三，在SDN网络中仅仅通过添加一系列流表规则来细粒度地分割流量是很难实现的。在论文 \citing{ParaTE2}中提出一种基于GPU的遗传算法来解决业务量工程问题，其目标函数是最小化最大链路利用率（MLU，minimize largest utilization），但是大量基于实际拓扑的实验表明，在网络利用率没有达到拥塞程度的时候，链路利用率效用函数，特别是最小化最大链路利用率，不是对业务量工程效果的较好评价函数 \citing{BeyondMLU}。反之，在网络链路发生拥塞的情况下，仅仅优化链路利用率，无法给出一个满足容量约束的可行解。

\subsection{SDN 弹性光网络下业务量工程算法的研究现状}
随着视频流、云计算服务和移动应用的普及，互联网的流量不断增加 \citing{EINC}，业务量的持续增长给互联网的传输带来了巨大的挑战。为了满足日益增长的流量需求，波分复用（WDM）系统已部署在骨干网络，其每个通道带宽高达40 GB/s或100 Gb/s。然而，传统的WDM光网络严格遵循ITU-T的固定均匀间距（通常为50GHz或100千兆赫) \citing{ETR}，这样会导致低效的频谱利用率，比如，一个较大的波长可能会被分配给一个低速率的业务，即使这个业务根本就不能占满整个波长。很明显，传统WDM光网络的不灵活和粗粒度的带宽控制会导致显著的频谱浪费，限制了提高其网络容量的潜力。

为了应对WDM网络的低敏捷性和频谱浪费问题，近年来，弹性光网络(EON)的架构被提出\citing{555}，在EON架构中，存在细粒度的带宽间隙（比如，12.5GHZ），他比WDM 网络所遵循的ITU标准的50GHZ或者100GHZ 的带宽粒度要小很多，而且，这些带宽间隙可以根据需要被组合在一起以提供更宽的通道，以灵活地适应各种速率的业务，提高频谱利用率。为了在EON网络中加入业务，控制平面必须在网络中找到一条路径，同时，还需要为业务在此路径上的链路上分配足够的频谱带宽，以创建一个合适的端到端光路连接，这被称为路由和频谱分配（RSA，routing and spectrum allocation）问题。

RSA问题可以进一步分为静态RSA问题和动态RSA问题。静态的RSA问题出现在网络规划阶段，其中流量需求是已知的，这样可以离线计算出最优解。动态RSA问题是指在实时情况下的业务路由选择和波长分配的优化问题，在动态RSA问题中，业务随机的到达和离开光网络，使得网络中的频谱资源不断变化，RSA问题变得更加困难。

论文\citing{wan}对动态RSA问题进行了研究，作者提出了三种算法，第一种是基于K最短路径的动态RSA算法，算法为每个业务求得前K条最短路径，并检查这些路径上的频谱资源是否足够，选择一条频谱足够的路径作为业务的路由，但是由于K最短路径是预先静态计算出来的，所以算法在网络状态动态变化的情况下表现很差。第二种算法被称为MSP(Modified Shortest Path)，MSP是基于dijkstra算法的，他在dijkstra最短路算法的计算过程中加入了对链路频谱的检查，从而得到满足频谱约束的路径，但是MSP算法的优化结果很糟糕。第三种算法被称为SPV（Spectrum Constraint Path Search)，SPV算法可以为业务寻找到满足频谱约束的最短路径，但是SPV算法的计算复杂度为一个指数函数，复杂度过高。

弹性光网络下的业务量工程问题等价于解决大量业务的RSA问题，也就是说弹性光网络下的业务量工程不仅要优化业务的路由代价，还要把业务安排到满足频谱约束的路径上，这使得弹性光网络下的业务量工程问题比IP网络中的业务量工程问题更加复杂。论文\citing{ELAYER}中提出一种分层图模型来解决WDM网络中的路由和波长分配问题，这种分层图模型也可以很容易地推广到EON网络中，这种分层图模型将频谱分配问题转化为路由选择问题，使得频谱分配和业务量工程问题统一起来。但是分层图模型会引入大量的辅助网络拓扑，我们需要在不同的拓扑上计算路由，这使得业务量工程的计算量大大增加。不过，幸运的是，这些辅助网络拓扑之间的路由计算是相互独立的，我们可以使用并行算法来加速这些路由的计算。

\section{论文内容及结构安排}
本文各个章节的内容如下：

第一章 简要介绍了SDN网络下的基于GPU的并行业务量工程算法的研究现状和意义。

第二章 简略介绍了GPU的相关基础原理，包括GPU架构和CUDA编程模型，以帮助理解第三、四章的GPU程序设计思路。

第三章首先将业务量工程问题建模成一个带链路容量约束的MILP模型。为了求解这个模型，本章分别讨论了两种并行算法GA-PTEA（Genetic algorithm based parallel traffic engineering algorithm）和LR-PTEA（Lagrange relaxing based parallel traffic engineering algorithm)。

第四章主要研究SDN弹性光网络中的业务量工程算法，为了简化频谱分配问题，本章采用分层图模型将弹性光网络中的频谱分配问题转化为路由选择问题。为了优化弹性光网络中业务的路由代价，减小资源使用，降低阻塞率，本章提出了TESAA（traffic engineering and spectrum allocate algrithm）优化算法，并对TESAA进行GPU加速设计。

\include{chapters/c1}
\include{chapters/c2}
\include{chapters/c3}
\chapter{全文总结与展望}
\section{全文总结}
本文主要研究了SDN网络下适合于并行计算的业务量工程算法框架，并且针对这些框架，设计基于GPU的并行算法。

本文首先简要介绍了GPU的并行优化原理，主要包括GPU与CPU的区别，GPU的架构特点和CUDA编程模式。

第三章在SDN IP网络中，本文将业务量工程问题建模成一个带链路容量约束的以路由代价为目标的MILP模型，为了解决这个MILP模型，本文提出了GA-PTEA和LR-PTEA两种基于GPU的并行算法，并对两种算法的GPU并行设计细节进行了讨论。并行算法GA-PTEA的加速比虽然可以达到20倍以上，但是由于遗传算法收敛缓慢的原因，其时间表现并不理想，另外由于遗传算法容易陷入局部最优解所以GA-PTEA求得的解比较差，但是本文中提出的带资源约束的并行遗传算法设计方法也可以应用到其他带资源约束情况下的优化问题中。LR-PTEA能够在短时间内得到业务量工程模型的优化解，说明拉格朗日松弛方法更加适合解决这种资源分配问题，对拉格朗日子问题的并行求解思想可以应用到其他的优化问题中，如果将优化问题的约束松弛进目标函数后，原优化问题可以被分解为独立的子问题，我们就可以使用并行算法来加速这些子问题的求解。

第四章针对SDN弹性光网络，本文采用分层图模型将频谱分配问题转化为路由选择问题，并且利用分层图之间的独立特性来设计并行的业务量工程算法PTESAA，利用GPU强大的并行计算能力，PTESAA在不同的分层图上搜索路径，在短时间内为业务的路由选择提供了更大的空间，从而优化了业务的路由代价，节省了网络资源的使用，降低阻塞率。第四章提出的并行BFS算法的并行粒度为$|E|$大大高于文献\ref{SSP}中提出的BFS算法的并行粒度(为$|N|$)。第四章提出的动态规划算法可以在伪多项式时间复杂度（$W_{max}\times|E|$）内解决带跳数约束的最短路径问题，能应用到更多的场景当中。

\section{后续工作展望}
GPU并不擅长分支较多的计算，GPU更加适合逻辑简单但计算量很大的任务加速，而路由算法中计算操作并不多，而大部分是逻辑计算，这也是为什么本文中的路由算法只能获得小于10倍加速的原因，而且本文中的算法只能在业务数量达到一定规模的情况下才能达到加速效果，本文只利用了GPU的并行处理能力，而没有充分利用GPU的大规模浮点计算能力，这也是GPU应用在路由算法上的限制，所以在今后的工作中可以挖掘更多的计算密集型的任务进行GPU加速。

在研究本次毕业设计的过程中，本人除了设计GA-PTEA，LR-PTEA和TESAA算法之外，还针对弹性光网络分层图上的网络流问题进行了基于GPU的并行化研究，本人对预流推进算法进行了并行化的设计并在其中加入跳限约束。但是由于算法逻辑复杂，加速效果并不好，只能在一些特殊情况，比如流很多的情况下才有一定的加速比，所以这部分工作并没有被写进本次设计，后续我将会继续改进这个预流推进算法，希望可以得到好的加速效果。
\thesisacknowledgement
首先我要感谢我的导师王雄老师，感谢他给我的一切。早在论文开题前，王老师就为我确定好了研究方向，使得我不再迷惘彷徨，在毕业设计的研究当中，我常常会因为自己的粗心大意和不严谨的做法导致错误而陷入困难当中，而王老师总是能够耐心的对我进行指导和鼓舞，使我重新找到自信去克服困难，而在论文的写作当中，王老师细致入微地分析我的论文，给我提出了宝贵的修改意见。王老师不仅仅是我科研上的导师，还是我精神上的导师，每每想起和王老师一起探讨算法时的场景，我就非常激动，是王老师让我感受到了算法的无穷魅力，让我找到了我人生想要追寻的方向！在生命的旅程中，能够遇到王老师是我一生的幸运，受用不尽，铭记在心。

其次，我要感谢我的父母，每当我遇到困难的时候，我的父母都能给我精神上的鼓舞，让我感受到家的温暖，正是因为有家的坚强后盾，我才能更加坚强的去追寻梦想。

我还要感谢我的同窗好友，感谢潘神在科研上和生活上对我的帮助，感谢兴爷的饭菜，感谢伟神的carry。我还要感谢实习时的同事，感谢万鹏飞博士对我在计算机视觉算法上的指导，感谢博哥对我在日常工作上的指导，感谢华哥对我在CUDA编程上的指导。

\begin{thebibliography}{1}
\bibitem{OpenFlow}
OpenFlow Switch Specification, https://www.opennetworking.org/images\newline/stories/downloads/sdn-resources/onf-specifications/openflow/openflow-switch-v1.5.0.noipr.pdf
\bibitem{SDN}
N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson, J. Rexford, S. Shenker, and J. Turner. Openflow: enabling innovation in campus networks. \emph{SIGCOMM Computer Communicaiton Review},2008,38(2),69-74.
\bibitem{SDN2}
N. McKeown. Software-defined networking[J]. \emph{INFOCOM keynote talk},2009,17(2),30-32.
\bibitem{SDN3}
Kim H,Feamster N. Improving network management with software defined networking. \emph{IEEE Communications Magazine},2013,51(2),114-119.
\bibitem{SDNSurvey1}
B. A. Nunes, M. Mendonca, X. Nguyen, K. Obraczka, and T. Turletti, A survey of software-defined networking :past, present, and future of programming networks, \emph{IEEE Communications Surveys \& Tutorials},2014,16(3),1617-1634.
\bibitem{SDNSurvey2}
R. Masoudi and A. Ghaffari, Software defined networks: a survey, Journal of Network and Computer Applications,2016,67,1-25.


\bibitem{Microsoft}
C.-Y. Hong, S. Kandula, R. Mahajan, M. Zhang, V. Gill, M. Nanduri, and R. Wattenhofer. Achieving high utilization with software-driven wan, \emph{in Proceedings of the ACM SIGCOMM},2013,15-26.
\bibitem{Google}
S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh, S. Venkata, J. Wanderer, J. Zhou, and M. Zhu et al. B4: Experience with a globally-deployed software defined wan, \emph{in Proceedings of the ACM SIGCOMM},2013,3-14.

\bibitem{application}
Cisco Visual Networking Index: Forecast and Methodology, 2016C2021, http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/complete-white-paper-c11-481360.html
\bibitem{5G}
S. S. Soliman and B. Song, Fifth generation (5G) cellular and the network for tomorrow, Journal of Network and Computer Applications,2017,85,84-93.
\bibitem{DCN}
C. Guo, L. Yuan, D. Xiang, et al. Pingmesh: a large-scale system for data center network latency measurement and analysis, \emph{ACM SIGCOMM}, 2015.
\bibitem{Secondrouting}
S. Gay, R. Hartert, and S. Vissicchio. Expect the unexpected:sub-second optimization ofr segment routing, \emph{IEEE INFOCOM}, 2017.
\bibitem{CUDA}
Nvidia. Programming guide: CUDA toolkit documentation, http://docs.nvidia.com/cuda/cuda\_c\_programming\_guide/index.html\#axzz4mVqP2TEC
\bibitem{Thrust}
Nvidia.Programming guide: CUDA toolkit documentation, http://docs.nvidia.com/cuda/pdf/Thrust\_Quick\_Start\_Guide.pdf.
\bibitem{CUDAR}
Jason Sanders,Edward Kandrot.GPU高性能之CUDA 实战[M],\emph{机械工业出版社},2011.

\bibitem{ParaTE1}
B. McCormick, F. Kelly, P. Plante, P. Gunning, and P. Ashwood-Smith. Real time alpha-fairness based traffic engineering, \emph{in Procedings of HotSDN}, 2014.
\bibitem{ParaTE2}
K. Kikuta, E. Oki, N. Yamanaka, N. Togawa, and H. Nakazato. Effective parallel algorithm for GPGPU-accelerated explicit routing optimization, \emph{in Procedings of GLOBECOM}, 2015.
\bibitem{TEDef}
Y. Lee and B. Mukherjee. Traffic engineering in next-generation optical networks, \emph{IEEE Communications Surveys \& Tutorials},2004,6(3),16-33.

\bibitem{TESurvey1}
A. Mendiola, J. Astorga, E. Jacob, and M. Higuero. A survey on the contributions of software-defined networking to traffic engineering, \emph{IEEE Communications Surveys \& Tutorials},2017,19(2),918-953.
\bibitem{TESurvey}
N. Wang, K. Ho, G. Pavlou, and M. Howarth. An overview of routing optimization for Internet traffic engineering, \emph{IEEE Communications Surveys \& Tutorials},2008,10(1),36-56.
\bibitem{NP}
Y. Wang and Z. Wang. Explicit routing algorithms for Internet traffic engineering, \emph{in Procedings of International Conference on Computer Communications and Networks}, 1999.

\bibitem{multi-commodity}
M. Pioro and D. Medhi. Routing, flow, and capacity design in communication and computer networks, Morgan Kaufmann Publishers, 2004.
\bibitem{SDNTE}
S. Agarwal, M. Kodialam, and T. V. Lakshman. Traffic engineering in software defined networks, \emph{in proceedings of INFOCOMM}, 2013.
\bibitem{Time}
J. Rexford. Route optimization in IP networks, \emph{in Handbook of Optimizationin Telecommunications}, Springer Science + Business Media, February 2006.

\bibitem{mate}
A. Elwalid, C. Jin, S. Low, and I. Widjaja. MATE: MPLS adaptive traffic engineering, \emph{in proceedings of INFOCOMM}, 2001.

\bibitem{DATE}
J. He, M. Chiang, and J. Rexford. DATE: distibuted adaptive traffic engineering, \emph{in proceedings of INFOCOMM}, 2006.

\bibitem{GPUdeve}
A. R. Brodtkorb, T. R. Hagen, C. Schulz, and G. Halse. GPU Computing in Discrete Optimization Part I: Introduction to the GPU, \emph{EURO Journal on Transportation and Logistics},2013,2(1),129-157.

\bibitem{TSP}
K. Rocki and R. Suda. Accelerating 2-opt and 3-opt local search using GPU in the travelling salesman problem, \emph{In Proceedings of IEEE/ACM International Conference on High Performance Computing
and Simulation (HPCS)},2012,489-495.
\bibitem{VRP}
C. Schulz. Efficient local search on the GPU - investigations on the vehicle routing problem, \emph{Journal of Parallel and Distributed Computing},2013,73(1),14-31.

\bibitem{SSP1}
P. Harish and P. J. Narayanan, Accelerating large graph algorithms on the GPU using CUDA. \emph{In Proceedings of International Conference on High performance Computing},2007,197-208.
\bibitem{SSP2}
Q. N. Tran. Designing efficient many-core parallel algorithms for all-pairs shortest-poaths using CUDA. \emph{In Proceedings of International Conference on Information Technology: New Generations},2010,7-12.
\bibitem{MST}
S. Rostrup, S. Srivastava, K. Singhal. Fast and memory-efficient minimum spanning tree on the GPU. \emph{In Proceedings of International Workshop on GPUs and Scientific Applications}, 20011.


\bibitem{MLU1}
S. Kandula, D. Katabi, B. Davie, and A. Charny. Walking the tightrope: responsive yet stable traffic engineering, \emph{in Procedings of ACM SIGCOMM},2005,253-264.
\bibitem{MLU2}
H. Wang, H. Xie, and L. Qiu. COPE: traffic engineering in dynamic networks, \emph{in Procedings of ACM SIGCOMM},2006,99-110.
\bibitem{Convex1}
B. Fortz and M. Thorup. Internet traffic engineering by optimizing OSPF weights, \emph{in Procedings of IEEE INFOCOM},2000,519-528.
\bibitem{Convex2}
D. Xu, M. Chiang, and J. Rexford. Link-state routing with hop-by-hop forwarding can achieve optimal traffic engineering, \emph{IEEE/ACM Transactions on Networking},2011,19(6),1717-1730.
\bibitem{BeyondMLU}
A. Sharma, A. Mishra, V. Kumar, and A. Venkataramani. Beyond MLU: an application-centric comparison of traffic engineering schemes, \emph{in Procedings of INFOCOM}, 2011.

\bibitem{NetworkFlow}
R. K. Ahuja, T. L. Magnanti, and J. B. Orlin, Network flows: Theory, Algorithms, and Applications, Prentice Hall, 1993.
\bibitem{ER}
P. Erdos and A. Renyi. On the evolution of random graphs. \emph{Publications of the Mathematical Institute of the Hungarian Academy of
Sciences},1960,5,17-61.
\bibitem{BA}
R. Albert and A. L. Barabasi. Statistical mechanics of complex networks. \emph{Reviews of Modern Physics}, 2002,74,47-97, 2002.
\bibitem{CPLEX}
IBM ILOG CPLEX Optimization Studio, https://www.ibm.com/bs-en/marketplace/ibm-ilog-cplex.

\bibitem{EINC}
A. A. M. Saleh and J. M. Simmons,Technology and architecture to enable the explosive growth of the Internet,\emph{IEEE Communication Magazine.},vol,49(1),126-132.
\bibitem{ELAB}
L. Zong, G. N. Liu, A. Lord, Y. R. Zhou and T. Ma.40/100/400 Gb/s mixed line rate transmission performance in flexgrid optical networks,\emph{in 2013 Optical Fiber Communication Conference,Anaheim},2013
\bibitem{EDF}
T. Wuth, M. W. Chbat, and V. F. kamalov, Multi-rate(100G/40G/10G) transport over deployed optical networks,\emph{in 2008 Optical Fiber Communication Conference,San Diego},2008.
\bibitem{ETR}
Spectral grids for WDM applications: DWDM frequencygrid,\emph{ITU-T},G.694.1.
\bibitem{ETRP1}
H. Zang, J. P. Jue, B. Mukherjee.A review of routing and wavelength assignment approaches for wavelengthrouted optical WDM networks,\emph{Optical Networks Magazine},2000,1,47-59.
\bibitem{ETRP2}
R. Ramaswami and K. N. Sivarajan,Routing and wavelength assignment in all-optical networks.\emph{IEEE Transactions on Networking},1995,3(5),489-500.
\bibitem{ELAYER}
敖发良 ,胡汉武,全光网静态路由选择和波长分配的分层图算法.\emph{光通信研究},vol.3,2003.
\bibitem{shen}
D. Awduche et. al,Overview and Principles of Internet Traffic Engineering. \emph{IETF, RFC 3272}, 313-324, 2003.
\bibitem{555}
M. Jinno, H. Takara, B. Kozicki, Y. Tsukishima, Y. Sone,and S. Matsuoka, Spectrum efficient and scalable elastic optical path network: architecture, benefits, and enabling technologies, \emph{IEEE Communication Magazine}, 2009,47(11),66-73.
\bibitem{wan}
X. Wan, L. Wang, N. Hua, H. Zhang, and X. Zheng,Dynamic routing and spectrum assignment in flexible optical path networks, \emph{in Optical Fiber Communication Conference}, 2011
\end{thebibliography}
\begin{thesisachievement}
\bibitem{1} 2015 研究生新生奖学金
\bibitem{2} 2016 研究生三等奖学金
\bibitem{3} 2016 华为软件精英挑战赛二等奖
\bibitem{4} 2017 研究生三等奖学金
\bibitem{5} 2017 华为软件精英挑战赛二等奖
\bibitem{6} 参与国家自然基金项目
\end{thesisachievement}
\end{document}


